{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1111676,"sourceType":"datasetVersion","datasetId":623289},{"sourceId":14288553,"sourceType":"datasetVersion","datasetId":9120333}],"dockerImageVersionId":31239,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T18:20:12.417635Z","iopub.execute_input":"2025-12-25T18:20:12.418039Z","iopub.status.idle":"2025-12-25T18:20:12.422830Z","shell.execute_reply.started":"2025-12-25T18:20:12.418012Z","shell.execute_reply":"2025-12-25T18:20:12.421918Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ================================================================================\n# CELL 1 - CHARGEMENT DES DONNEES\n# ================================================================================\n\nimport numpy as np\nimport pickle\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import make_scorer, f1_score, hamming_loss, accuracy_score, recall_score, precision_score\nfrom sklearn.cluster import KMeans as SegmentationKMeans\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom collections import Counter\n\nprint(\"Loading data...\")\nX = np.load(\"/kaggle/input/dataset-pre-traitement-sift-bovw-pca/X_pca.npy\")\ny = np.load(\"/kaggle/input/dataset-pre-traitement-sift-bovw-pca/y.npy\")\n\nwith open(\"/kaggle/input/dataset-pre-traitement-sift-bovw-pca/label_names.pkl\", \"rb\") as f:\n    label_names = pickle.load(f)\n\nprint(f\"Data loaded successfully!\")\nprint(f\"X shape: {X.shape}\")\nprint(f\"y shape: {y.shape}\")\nprint(f\"Number of labels: {len(label_names)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T18:20:12.702616Z","iopub.execute_input":"2025-12-25T18:20:12.702954Z","iopub.status.idle":"2025-12-25T18:20:12.739171Z","shell.execute_reply.started":"2025-12-25T18:20:12.702929Z","shell.execute_reply":"2025-12-25T18:20:12.738271Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nData loaded successfully!\nX shape: (8091, 100)\ny shape: (8091, 495)\nNumber of labels: 495\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ================================================================================\n# CELL 2 - DIVISION TRAIN / TEST\n# ================================================================================\n\n# Utiliser les variables de la cellule 1\n# X, y, label_names doivent être chargés\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    random_state=42\n)\n\nprint(f\"Training set size: {X_train.shape[0]}\")\nprint(f\"Test set size: {X_test.shape[0]}\")\nprint(f\"Number of features: {X_train.shape[1]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T18:20:12.740450Z","iopub.execute_input":"2025-12-25T18:20:12.740861Z","iopub.status.idle":"2025-12-25T18:20:12.769015Z","shell.execute_reply.started":"2025-12-25T18:20:12.740833Z","shell.execute_reply":"2025-12-25T18:20:12.768252Z"}},"outputs":[{"name":"stdout","text":"Training set size: 6472\nTest set size: 1619\nNumber of features: 100\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ================================================================================\n# CELL 3 - NORMALISATION ET ENTRAÎNEMENT\n# ================================================================================\n\n\nimport time\n\nprint(\"Normalizing features...\")\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\nprint(\"Features normalized!\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"STARTING GRIDSEARCH\")\nprint(\"=\"*60)\n\ngb_classifier = GradientBoostingClassifier(\n    random_state=42,\n    verbose=0\n)\n\novr_model = OneVsRestClassifier(gb_classifier, n_jobs=-1)\n\nparam_grid = {\n    'estimator__n_estimators': [200],\n    'estimator__max_depth': [6],\n    'estimator__learning_rate': [0.08]\n}\n\nf1_scorer = make_scorer(f1_score, average='samples', zero_division=0)\n\ngrid_search = GridSearchCV(\n    estimator=ovr_model,\n    param_grid=param_grid,\n    scoring=f1_scorer,\n    cv=5,\n    verbose=2,\n    n_jobs=1,\n    return_train_score=True\n)\n\nprint(\"\\nStarting GridSearch...\")\nstart_time = time.time()\ngrid_search.fit(X_train_scaled, y_train)\ntrain_time = time.time() - start_time\nprint(\"GridSearch completed!\")\n\nmodel = grid_search.best_estimator_\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"BEST PARAMETERS FOUND\")\nprint(\"=\"*60)\nfor param, value in grid_search.best_params_.items():\n    print(f\"{param}: {value}\")\nprint(f\"\\nBest CV F1 Score: {grid_search.best_score_:.4f}\")\nprint(f\"Training time: {train_time/60:.2f} minutes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T18:20:13.005256Z","iopub.execute_input":"2025-12-25T18:20:13.005605Z"}},"outputs":[{"name":"stdout","text":"Normalizing features...\nFeatures normalized!\n\n============================================================\nSTARTING GRIDSEARCH\n============================================================\n\nStarting GridSearch...\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# CELL 4 - EVALUATION INITIALE\n# ================================================================================\n\n# Utiliser les variables des cellules précédentes\n# model, X_test_scaled, y_test doivent être définis\n\nprint(\"Making predictions...\")\ny_pred_initial = model.predict(X_test_scaled)\n\naccuracy = accuracy_score(y_test, y_pred_initial)\nf1 = f1_score(y_test, y_pred_initial, average='samples', zero_division=0)\nrecall = recall_score(y_test, y_pred_initial, average='samples', zero_division=0)\nprecision = precision_score(y_test, y_pred_initial, average='samples', zero_division=0)\nhamming = hamming_loss(y_test, y_pred_initial)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"INITIAL EVALUATION\")\nprint(\"=\"*60)\nprint(f\"\\nAccuracy: {accuracy:.4f}\")\nprint(f\"F1 Score (samples): {f1:.4f}\")\nprint(f\"Recall (samples): {recall:.4f}\")\nprint(f\"Precision (samples): {precision:.4f}\")\nprint(f\"Hamming Loss: {hamming:.4f}\")\n\nf1_macro = f1_score(y_test, y_pred_initial, average='macro', zero_division=0)\nf1_micro = f1_score(y_test, y_pred_initial, average='micro', zero_division=0)\nprint(f\"\\nF1 Score (macro): {f1_macro:.4f}\")\nprint(f\"F1 Score (micro): {f1_micro:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================================================================\n# CELL 5 - OPTIMISATION DU SEUIL ET PROBABILITES\n# ================================================================================\n\n# Utiliser les variables des cellules précédentes\n# model, X_test_scaled, y_test, label_names doivent être définis\n\nprint(\"Initializing MultiLabelBinarizer...\")\nmlb = MultiLabelBinarizer()\nmlb.classes_ = np.array(label_names)\n\ndef predict_with_threshold(model, X, threshold=0.3):\n    n_samples = X.shape[0]\n    n_labels = len(model.estimators_)\n    y_proba = np.zeros((n_samples, n_labels))\n    \n    for i, est in enumerate(model.estimators_):\n        if hasattr(est, 'predict_proba'):\n            proba = est.predict_proba(X)\n            if proba.shape[1] == 2:\n                y_proba[:, i] = proba[:, 1]\n            else:\n                y_proba[:, i] = proba[:, 0]\n    \n    y_pred = (y_proba >= threshold).astype(int)\n    return y_pred, y_proba\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"FINDING BEST THRESHOLD\")\nprint(\"=\"*60)\n\nthresholds = [0.2, 0.3, 0.4, 0.5]\nbest_threshold = 0.3\nbest_recall = 0\nresults = []\n\nfor t in thresholds:\n    y_pred_t, _ = predict_with_threshold(model, X_test_scaled, threshold=t)\n    r = recall_score(y_test, y_pred_t, average='samples', zero_division=0)\n    p = precision_score(y_test, y_pred_t, average='samples', zero_division=0)\n    f = f1_score(y_test, y_pred_t, average='samples', zero_division=0)\n    results.append((t, r, p, f))\n    \n    print(f\"Threshold {t}: Recall={r:.4f}, Precision={p:.4f}, F1={f:.4f}\")\n    \n    if r > best_recall:\n        best_recall = r\n        best_threshold = t\n\nprint(f\"\\nBest threshold: {best_threshold} with recall {best_recall:.4f}\")\n\nprint(\"\\nComputing probabilities with best threshold...\")\ny_pred, y_proba = predict_with_threshold(model, X_test_scaled, threshold=best_threshold)\nprint(\"Probabilities computed!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" #================================================================================\n# CELL 6 - GENERATION DE PHRASES ET AFFICHAGE\n# ================================================================================\n\n# Utiliser les variables des cellules précédentes\n# y_pred, y_proba, y_test, label_names, mlb doivent être définis\n\ndef generate_sentence_from_keywords(keywords, proba=None):\n    if len(keywords) == 0:\n        return \"No keywords detected\"\n    \n    if proba is not None:\n        keywords = [kw for kw, _ in sorted(zip(keywords, proba), key=lambda x: x[1], reverse=True)]\n    \n    if len(keywords) == 1:\n        return f\"An image of {keywords[0]}\"\n    elif len(keywords) == 2:\n        return f\"An image showing {keywords[0]} and {keywords[1]}\"\n    elif len(keywords) == 3:\n        return f\"An image of {keywords[0]} with {keywords[1]} and {keywords[2]}\"\n    else:\n        main_kw = ', '.join(keywords[:3])\n        return f\"An image featuring {main_kw} and {keywords[3]}\"\n\nIMAGE_DIR = \"/kaggle/input/flickr8k/Images\"\nvalid_image_names = os.listdir(IMAGE_DIR)\n\ndef predict_and_display_improved(idx, X_test, y_test, y_pred, y_proba):\n    pred_idx = np.where(y_pred[idx] == 1)[0]\n    pred_labels = mlb.classes_[pred_idx]\n    pred_probs = y_proba[idx][pred_idx]\n    \n    true_idx = np.where(y_test[idx] == 1)[0]\n    true_labels = mlb.classes_[true_idx]\n    \n    img_name = valid_image_names[idx]\n    img_path = os.path.join(IMAGE_DIR, img_name)\n    img = cv2.imread(img_path)\n    if img is None:\n        print(f\"Cannot load image {img_path}\")\n        return\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    caption = generate_sentence_from_keywords(list(pred_labels), pred_probs)\n    \n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.imshow(img_rgb)\n    plt.axis('off')\n    plt.title(img_name, fontsize=12, fontweight='bold')\n    \n    plt.subplot(1, 2, 2)\n    plt.axis('off')\n    text = f\"PREDICTED KEYWORDS:\\n\"\n    for kw, p in zip(pred_labels, pred_probs):\n        text += f\" • {kw} ({p:.2f})\\n\"\n    text += f\"\\nGENERATED CAPTION:\\n{caption}\\n\"\n    plt.text(0, 0.5, text, fontsize=11, verticalalignment='center',\n             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n    plt.tight_layout()\n    plt.show()\n    \n    return pred_labels, caption, true_labels\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"PREDICTIONS ON TEST IMAGES\")\nprint(\"=\"*60)\n\nfor i in range(min(5, len(X_test))):\n    print(f\"\\nImage {i+1}:\")\n    predict_and_display_improved(i, X_test_scaled, y_test, y_pred, y_proba)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================================================================\n# CELL 7 - SEGMENTATION D'IMAGE\n# ================================================================================\n\n# Utiliser les variables des cellules précédentes\n\ndef segment_image_kmeans(image_path, n_segments=5, show_result=True):\n    image = cv2.imread(image_path)\n    if image is None:\n        print(f\"Error: cannot load {image_path}\")\n        return None, None, None\n    \n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    h, w, c = image_rgb.shape\n    pixels = image_rgb.reshape(-1, 3)\n    pixels_normalized = pixels.astype(np.float32) / 255.0\n    \n    print(f\"Segmentation with K-means (k={n_segments})...\")\n    kmeans_seg = SegmentationKMeans(\n        n_clusters=n_segments,\n        random_state=42,\n        n_init=10,\n        max_iter=300\n    )\n    \n    labels = kmeans_seg.fit_predict(pixels_normalized)\n    centers = kmeans_seg.cluster_centers_\n    \n    segmented_pixels = centers[labels]\n    segmented_image = (segmented_pixels * 255).reshape(h, w, c).astype(np.uint8)\n    labels_image = labels.reshape(h, w)\n    \n    if show_result:\n        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n        \n        axes[0].imshow(image_rgb)\n        axes[0].set_title('Original Image', fontsize=14, fontweight='bold')\n        axes[0].axis('off')\n        \n        axes[1].imshow(segmented_image)\n        axes[1].set_title(f'K-means Segmentation (k={n_segments})', fontsize=14, fontweight='bold')\n        axes[1].axis('off')\n        \n        im = axes[2].imshow(labels_image, cmap='tab20')\n        axes[2].set_title('Segmented Regions', fontsize=14, fontweight='bold')\n        axes[2].axis('off')\n        plt.colorbar(im, ax=axes[2], fraction=0.046)\n        \n        plt.tight_layout()\n        plt.show()\n        \n        unique_labels, counts = np.unique(labels, return_counts=True)\n        print(f\"\\nNumber of segments: {len(unique_labels)}\")\n        print(\"\\nSegment sizes (in pixels):\")\n        for label, count in zip(unique_labels, counts):\n            percentage = (count / len(labels)) * 100\n            print(f\"  Segment {label}: {count} pixels ({percentage:.2f}%)\")\n    \n    return segmented_image, labels_image, centers\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"IMAGE SEGMENTATION\")\nprint(\"=\"*60)\n\nseg_img1, labels1, centers1 = segment_image_kmeans(\n    \"/kaggle/input/flickr8k/Images/1022454332_6af2c1449a.jpg\", \n    n_segments=5, \n    show_result=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================================================================\n# CELL 8 - METRIQUES BLEU ET CIDER\n# ================================================================================\n\n# Utiliser les variables des cellules précédentes\n# y_pred, y_test, mlb, label_names doivent être définis\n\ndef calculate_bleu_scores(ref, hyp):\n    def ngrams(tokens, n):\n        return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n    scores = []\n    for n in range(1, 5):\n        ref_ngrams = ngrams(ref, n)\n        hyp_ngrams = ngrams(hyp, n)\n        if len(hyp_ngrams) == 0:\n            scores.append(0)\n        else:\n            overlap = sum(1 for g in hyp_ngrams if g in ref_ngrams)\n            scores.append(overlap / len(hyp_ngrams))\n    return scores\n\ndef calculate_cider_score(ref_kw, hyp_kw):\n    if len(ref_kw) == 0 or len(hyp_kw) == 0:\n        return 0\n    \n    ref_counter = Counter(ref_kw)\n    hyp_counter = Counter(hyp_kw)\n    all_words = set(ref_kw) | set(hyp_kw)\n    \n    ref_vec = {w: ref_counter.get(w, 0) for w in all_words}\n    hyp_vec = {w: hyp_counter.get(w, 0) for w in all_words}\n    \n    dot = sum(ref_vec[w] * hyp_vec[w] for w in all_words)\n    norm = (sum(v*v for v in ref_vec.values())**0.5) * (sum(v*v for v in hyp_vec.values())**0.5)\n    \n    return (dot / norm) * 10 if norm > 0 else 0\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"COMPUTING BLEU AND CIDER SCORES\")\nprint(\"=\"*60)\n\nbleu1_scores, bleu2_scores, bleu3_scores, bleu4_scores, cider_scores = [], [], [], [], []\n\nfor i in range(len(X_test)):\n    pred_idx = np.where(y_pred[i] == 1)[0]\n    pred_kw = list(mlb.classes_[pred_idx])\n    true_idx = np.where(y_test[i] == 1)[0]\n    true_kw = list(mlb.classes_[true_idx])\n    \n    b1, b2, b3, b4 = calculate_bleu_scores(true_kw, pred_kw)\n    bleu1_scores.append(b1)\n    bleu2_scores.append(b2)\n    bleu3_scores.append(b3)\n    bleu4_scores.append(b4)\n    \n    cider = calculate_cider_score(true_kw, pred_kw)\n    cider_scores.append(cider)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"BLEU AND CIDER SCORES\")\nprint(\"=\"*60)\nprint(f\"Average BLEU-1: {np.mean(bleu1_scores):.4f}\")\nprint(f\"Average BLEU-2: {np.mean(bleu2_scores):.4f}\")\nprint(f\"Average BLEU-3: {np.mean(bleu3_scores):.4f}\")\nprint(f\"Average BLEU-4: {np.mean(bleu4_scores):.4f}\")\nprint(f\"Average CIDEr: {np.mean(cider_scores):.4f}\")\n\nprint(\"\\nBLEU Scores Statistics:\")\nprint(f\"BLEU-1 - Min: {np.min(bleu1_scores):.4f}, Max: {np.max(bleu1_scores):.4f}, Std: {np.std(bleu1_scores):.4f}\")\nprint(f\"BLEU-2 - Min: {np.min(bleu2_scores):.4f}, Max: {np.max(bleu2_scores):.4f}, Std: {np.std(bleu2_scores):.4f}\")\nprint(f\"BLEU-3 - Min: {np.min(bleu3_scores):.4f}, Max: {np.max(bleu3_scores):.4f}, Std: {np.std(bleu3_scores):.4f}\")\nprint(f\"BLEU-4 - Min: {np.min(bleu4_scores):.4f}, Max: {np.max(bleu4_scores):.4f}, Std: {np.std(bleu4_scores):.4f}\")\nprint(f\"CIDEr  - Min: {np.min(cider_scores):.4f}, Max: {np.max(cider_scores):.4f}, Std: {np.std(cider_scores):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================================================================\n# CELL 9 - SAUVEGARDE DU MODELE ET ARTIFACTS\n# ================================================================================\n\n# Utiliser les variables des cellules précédentes\n# model, scaler, label_names doivent être définis\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SAVING MODEL AND ARTIFACTS\")\nprint(\"=\"*60)\n\nwith open(\"/kaggle/working/gb_model_sift.pkl\", 'wb') as f:\n    pickle.dump(model, f)\nprint(\"Model saved: /kaggle/working/gb_model_sift.pkl\")\n\nwith open(\"/kaggle/working/scaler_sift.pkl\", 'wb') as f:\n    pickle.dump(scaler, f)\nprint(\"Scaler saved: /kaggle/working/scaler_sift.pkl\")\n\nwith open(\"/kaggle/working/label_names_sift.pkl\", 'wb') as f:\n    pickle.dump(label_names, f)\nprint(\"Label names saved: /kaggle/working/label_names_sift.pkl\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"PROCESS COMPLETED SUCCESSFULLY\")\nprint(\"=\"*60)\nprint(\"\\nAll models and artifacts have been saved to /kaggle/working/\")\nprint(\"You can now use these files for predictions on new images.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}