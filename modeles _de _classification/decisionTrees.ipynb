{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14288553,"sourceType":"datasetVersion","datasetId":9120333}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install iterative-stratification\n\nimport numpy as np\nimport pickle\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import precision_score, f1_score, accuracy_score, recall_score, hamming_loss\n\n# 1. Chargement des données\nX = np.load('/kaggle/input/dataset-pre-traitement-sift-bovw-pca/X_pca.npy')\ny = np.load('/kaggle/input/dataset-pre-traitement-sift-bovw-pca/y.npy')\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# 2. Définition de la stratégie de validation (k=8)\nmskf = MultilabelStratifiedKFold(n_splits=8, shuffle=True, random_state=42)\n\n# 3. Configuration du modèle selon One-vs-Rest\nbase_estimator = DecisionTreeClassifier(random_state=42)\novr_model = OneVsRestClassifier(base_estimator)\n\n# 4. Définition des d'hyperparamètres pour le Grid Search\nparam_grid = {\n    'estimator__max_depth': [10, 20, 30],\n    'estimator__min_samples_split': [2, 10],\n    'estimator__criterion': ['gini', 'entropy']\n}\n\n# 5. Grid Search\nprint(\"Début de l'optimisation par Grid Search (k=8)...\")\ngrid_search = GridSearchCV(\n    ovr_model, \n    param_grid, \n    cv=mskf, \n    scoring='f1_samples',\n    n_jobs=-1\n)\n\ngrid_search.fit(X_train, y_train)\n\n# 6. Modèle final optimisé\nbest_model = grid_search.best_estimator_\n\n# 7. Évaluation\ny_pred = best_model.predict(X_test)\nprint(\"-\" * 30)\nprint(f\"Accuracy (Subset) : {accuracy_score(y_test, y_pred):.4f}\")\nprint(f\"Précision : {precision_score(y_test, y_pred, average ='samples'):.4f}\")\nprint(f\"Recall  : {recall_score(y_test, y_pred, average = 'samples'):.4f}\")\nprint(f\"F1-Score : {f1_score(y_test, y_pred, average = 'samples'):.4f}\")\nprint(f\"Hamming Loss      : {hamming_loss(y_test, y_pred):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}